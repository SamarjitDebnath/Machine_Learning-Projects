# Traditional Machine Learning Algorithms

This directory contains a single notebook, `traditional_ml_algorithms.ipynb`, where various traditional machine learning algorithms are implemented for learning purposes. The notebook is designed to be run on Google Colab for easy access and execution in a cloud-based environment.

## Objectives

- **Learn by doing**: Implement algorithms from scratch to reinforce the understanding of their inner workings.
- **Build intuition**: Explore how algorithms perform on different datasets.
- **Improve coding skills**: Practice clean and efficient Python programming in a Jupyter Notebook environment.

## Contents

- **`traditional_ml_algorithms.ipynb`**: A Jupyter notebook hosted on Google Colab that includes step-by-step implementations of various machine learning algorithms, including:
  - **Linear Regression**
  - **Logistic Regression**
  - **Decision Trees**
  - **Naive Bayes** [WIP]
  - **K-Nearest Neighbors (KNN)** [WIP]
  - **Support Vector Machines (SVM)** [WIP]
  - **K-Means Clustering** [WIP]
  - **AdaBoost** [WIP]

## Getting Started

### Prerequisites

- A Google account to use Google Colab (free to sign up).
- Basic knowledge of machine learning and Python programming.

### Opening the Notebook

- You can either:
   - **Upload** the notebook to Google Colab and run it.
   - **Clone this repository** to your local machine and run the notebook using Jupyter:
     ```bash
     git clone [https://github.com/your-username/your-repo-name.git](https://github.com/SamarjitDebnath/Machine_Learning-Projects.git)
     cd machine_learning/traditional_algorithms
     jupyter notebook traditional_ml_algorithms.ipynb
     ```

### Running the Code

1. Open the notebook in **Google Colab** or **Jupyter** after downloading or cloning.
2. **Run each cell** to execute the code and see the implementations of the algorithms.
3. **Experiment** by modifying parameters and datasets to observe how the models behave.

## Examples

- **Linear Regression**: 
   - Fits a linear model to a synthetic dataset and visualizes the predictions.
   
- **K-Nearest Neighbors**:
   - Classifies points in a 2D space and plots the decision boundaries.

## Contributing

If you'd like to contribute to this project:
1. Fork the repository.
2. Create a feature branch (`git checkout -b feature/your-feature`).
3. Commit your changes (`git commit -m 'Add your feature'`).
4. Push to the branch (`git push origin feature/your-feature`).
5. Open a Pull Request.
